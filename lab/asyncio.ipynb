{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4256bd68",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99adae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def count():\n",
    "    print(\"One\")\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"Two\")\n",
    "    await asyncio.sleep(1)\n",
    "\n",
    "async def main():\n",
    "    await asyncio.gather(count(), count(), count())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    await main()\n",
    "    elapsed = time.perf_counter() - start\n",
    "    print(f\"{__name__} executed in {elapsed:0.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41a87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "from requests import get, Response\n",
    "\n",
    "async def get_response(url: str = \"\") -> None:\n",
    "    result: Response = get(url)\n",
    "    print(f\"{result.status_code}\")\n",
    "    return result.status_code, result.text\n",
    "\n",
    "url_paths: list[str] = [\n",
    "    \"https://google.com\",\n",
    "    \"https://yahoo.com\",\n",
    "    \"https://bing.com\",\n",
    "]\n",
    "\n",
    "async def main():\n",
    "    start_time: float = time.perf_counter()\n",
    "    await asyncio.gather(\n",
    "        *(get_response(url) for url in url_paths)\n",
    "    )\n",
    "    end_time: float = time.perf_counter()\n",
    "    print(f\"Processing time: {end_time - start_time = :.2f} (s)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc34953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import traceback\n",
    "\n",
    "\n",
    "async def check_by_aiohttp(session: aiohttp.ClientSession, url: str):\n",
    "    try:\n",
    "        async with session.get(url) as res:\n",
    "            print(f\"{url}: status -> {res.status}\")\n",
    "            if res.status != 200:\n",
    "                response_error: str = await res.text()\n",
    "                print(f\"{response_error = }\")\n",
    "    except Exception as e:\n",
    "        print(f\"{url}: error -> {e}\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    try:\n",
    "        websites = [\n",
    "            \"https://realpython.com\",\n",
    "            \"https://pycoders.com\",\n",
    "            \"https://www.python.org\",\n",
    "            \"https://google.com\",\n",
    "            \"https://yahoo.com\",\n",
    "            \"https://bing.com\",\n",
    "            \"https://non-exist.com\",\n",
    "        ]\n",
    "\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            results = await asyncio.gather(\n",
    "                *(check_by_aiohttp(session, url) for url in websites),\n",
    "                # return_exceptions=True\n",
    "            )\n",
    "\n",
    "    except Exception as e:\n",
    "        tb_str = \"\".join(traceback.TracebackException.from_exception(e).format())\n",
    "        print(f\"[{main.__name__}] Exception during processing:\\n{tb_str}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main() # for running on file .ipynb\n",
    "    # asyncio.run(main(), debug=True) # For running in file .py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33a1599",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e06a589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== Example 1: test response status with asyncio ==============================\n",
      "https://www.python.org: status -> 200\n",
      "https://google.com: status -> 200\n",
      "[check_by_aiohttp] [https://non-exist.com] Error: Cannot connect to host non-exist.com:443 ssl:True [SSLCertVerificationError: (1, \"[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'non-exist.com'. (_ssl.c:1016)\")]\n",
      "https://bing.com: status -> 200\n",
      "https://realpython.com: status -> 200\n",
      "https://yahoo.com: status -> 429\n",
      "[check_by_aiohttp] [https://yahoo.com] Response error: response_error = 'Edge: Too Many Requests'\n",
      "https://pycoders.com: status -> 200\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import traceback\n",
    "\n",
    "# ========== Example 1: test response status with asyncio ===========\n",
    "print(f\"{'':=<30} Example 1: test response status with asyncio {'':=>30}\")\n",
    "\n",
    "async def check_by_aiohttp(session: aiohttp.ClientSession, url: str):\n",
    "    try:\n",
    "        async with session.get(url) as res:\n",
    "            print(f\"{url}: status -> {res.status}\")\n",
    "            if res.status != 200:\n",
    "                response_error: str = await res.text()\n",
    "                print(f\"[{check_by_aiohttp.__name__}] [{url}] Response error: {response_error = }\")\n",
    "    except Exception as e:\n",
    "        print(f\"[{check_by_aiohttp.__name__}] [{url}] Error: {e}\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    try:\n",
    "        websites = [\n",
    "            \"https://realpython.com\",\n",
    "            \"https://pycoders.com\",\n",
    "            \"https://www.python.org\",\n",
    "            \"https://google.com\",\n",
    "            \"https://yahoo.com\",\n",
    "            \"https://bing.com\",\n",
    "            \"https://non-exist.com\",\n",
    "        ]\n",
    "\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            results = await asyncio.gather(\n",
    "                *(check_by_aiohttp(session, url) for url in websites),\n",
    "                return_exceptions=True\n",
    "            )\n",
    "\n",
    "    except Exception as e:\n",
    "        tb_str = \"\".join(traceback.TracebackException.from_exception(e).format())\n",
    "        print(f\"[{main.__name__}] Exception during processing:\\n{tb_str}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()\n",
    "    # asyncio.run(main(), debug=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7448685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== Example 2: test response status with asyncio ==============================\n",
      "[get_response] [https://google.com] Status: 200\n",
      "[get_google_response] [https://google.com] Result: True\n",
      "[get_python_response] [https://google.com] Result: True\n",
      "[get_python_response] New result: Hi\n",
      "[main] First res: Correct\n",
      "[main] Second res: 2025-11-22 HH:MM:SS\n",
      "[get_response] [https://google.com] Status: 200\n",
      "[get_google_response] [https://google.com] Result: True\n",
      "[get_response] [https://www.python.org] Status: 200\n",
      "[get_google_response] [https://www.python.org] Result: True\n",
      "<Task pending name='Task-125' coro=<get_google_response() running at /tmp/ipykernel_280/859564974.py:18>>\n",
      "[get_response] [https://google.com] Status: 200\n",
      "[get_google_response] [https://google.com] Result: True\n",
      "[get_response] [https://google.com] Status: 200\n",
      "[get_google_response] [https://google.com] Result: True\n",
      "[get_response] [https://www.python.org] Status: 200\n",
      "[get_google_response] [https://www.python.org] Result: True\n",
      "[main] Third res: 37\n",
      "{\n",
      "    \"gg_url\": \"https://google.com\",\n",
      "    \"other_url\": \"https://www.python.org\",\n",
      "    \"python_res\": \"Hi\",\n",
      "    \"first_sync_res\": \"Correct\",\n",
      "    \"second_sync_res\": \"2025-11-22 HH:MM:SS\",\n",
      "    \"gg_res\": true,\n",
      "    \"other_res\": true,\n",
      "    \"new_gg_res\": true,\n",
      "    \"new_other_res\": true,\n",
      "    \"third_sync_res\": 37\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ========== Example 2: test response status with asyncio ===========\n",
    "print(f\"{'':=<30} Example 2: test response status with asyncio {'':=>30}\")\n",
    "\n",
    "async def get_response(session: aiohttp.ClientSession, input_url: str = \"\") -> bool:\n",
    "    try:\n",
    "        res = await session.get(url=input_url)\n",
    "        async with res:\n",
    "            print(f\"[{get_response.__name__}] [{input_url}] Status: {res.status}\")\n",
    "            if res.status != 200:\n",
    "                response_error: str = await res.text()\n",
    "                print(f\"[{get_response.__name__}] [{input_url}] Response error: {response_error = }\")\n",
    "                return False\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"[{get_response.__name__}] [{input_url}] Error: {e}\")\n",
    "        return False\n",
    "\n",
    "async def get_google_response(session: aiohttp.ClientSession, url: str = \"\") -> str:\n",
    "    result = await get_response(session, url)\n",
    "    print(f\"[{get_google_response.__name__}] [{url}] Result: {result}\")\n",
    "    return result\n",
    "\n",
    "async def get_python_response(session: aiohttp.ClientSession, url: str = \"\") -> str:\n",
    "    result = await get_google_response(session, url)\n",
    "    print(f\"[{get_python_response.__name__}] [{url}] Result: {result}\")\n",
    "    new_res: str = \"Hi\" if result else \"Ho\"\n",
    "    print(f\"[{get_python_response.__name__}] New result: {new_res}\")\n",
    "    return new_res\n",
    "\n",
    "async def main():\n",
    "    import datetime\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        return_data: dict = {\n",
    "            \"gg_url\": \"https://google.com\",\n",
    "            \"other_url\": \"https://www.python.org\"\n",
    "        }\n",
    "\n",
    "        python_res: str = await get_python_response(session, return_data[\"gg_url\"])\n",
    "        return_data[\"python_res\"] = python_res\n",
    "\n",
    "        return_data[\"first_sync_res\"] = \"Correct\" if 1 < 2 else \"Incorrect\"\n",
    "        print(f\"[{main.__name__}] First res: {return_data['first_sync_res']}\")\n",
    "        return_data[\"second_sync_res\"] = datetime.datetime.now().strftime(\"%Y-%m-%d HH:MM:SS\")\n",
    "        print(f\"[{main.__name__}] Second res: {return_data['second_sync_res']}\")\n",
    "\n",
    "        # in this way, i'm doing it sequently, not true parallel(gg_res run => wait gg_res complete => run other_res). if gg_res: str = get_google_response block, maybe other_res can not run\n",
    "        gg_res: str = await get_google_response(session, return_data[\"gg_url\"])\n",
    "        return_data[\"gg_res\"] = gg_res\n",
    "\n",
    "        other_res: str = await get_google_response(session, return_data[\"other_url\"])\n",
    "        return_data[\"other_res\"] = gg_res\n",
    "\n",
    "        # to be true async\n",
    "        true_async_gg_res = asyncio.create_task(get_google_response(session, return_data[\"gg_url\"])) # return what? data type?\n",
    "        print(asyncio.create_task(get_google_response(session, return_data[\"gg_url\"])))\n",
    "        trye_async_other_res = asyncio.create_task(get_google_response(session, return_data[\"other_url\"]))\n",
    "        new_gg_res: str = await true_async_gg_res\n",
    "        return_data[\"new_gg_res\"] = new_gg_res\n",
    "        new_other_res: str = await trye_async_other_res\n",
    "        return_data[\"new_other_res\"] = new_other_res\n",
    "\n",
    "        import random\n",
    "        return_data[\"third_sync_res\"] = random.randint(10, 50)\n",
    "        print(f\"[{main.__name__}] Third res: {return_data['third_sync_res']}\")\n",
    "\n",
    "        return return_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import json\n",
    "    result = await main()\n",
    "    print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eb961f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In main\n",
      "sleeping: 1 1763811050.1316621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awaiting sleep: 1 1763811053.1319177\n",
      "sleeping: 2 1763811053.1321878\n",
      "awaiting sleep: 2 1763811056.1323824\n",
      "sleeping: 3 1763811056.132628\n",
      "awaiting sleep: 3 1763811059.1328528\n",
      "woke up: 1 1763811059.1334567\n",
      "woke up: 2 1763811059.133513\n",
      "woke up: 3 1763811061.13581\n"
     ]
    }
   ],
   "source": [
    "# Source - https://stackoverflow.com/a\n",
    "# Posted by sajid\n",
    "# Retrieved 2025-11-21, License - CC BY-SA 4.0\n",
    "\n",
    "# Python 3.9.6\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "\n",
    "async def test(name: str):\n",
    "    print(f\"sleeping: {name}\", time.time())\n",
    "    time.sleep(3) # imagine that this is big chunk of code/ or a number     crunching block that takes a while to execute\n",
    "\n",
    "    print(f\"awaiting sleep: {name}\", time.time())\n",
    "    await asyncio.sleep(2)\n",
    "\n",
    "    print(f\"woke up: {name}\", time.time())\n",
    "\n",
    "\n",
    "async def main():\n",
    "    print(\"In main\")\n",
    "    tasks = [test(name=\"1\"), test(name=\"2\"), test(name=\"3\")]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072f67ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "# import aiohttp\n",
    "# import async_timeout\n",
    "# import random\n",
    "# import time\n",
    "\n",
    "# MAX_CONCURRENCY = 200      # you can try 500â€“2000 depending on server\n",
    "# RETRIES = 3\n",
    "# TIMEOUT = 5\n",
    "\n",
    "# semaphore = asyncio.Semaphore(MAX_CONCURRENCY)\n",
    "\n",
    "\n",
    "# async def fetch(session, url):\n",
    "#     \"\"\"Raw fetch call with timeout.\"\"\"\n",
    "#     async with async_timeout.timeout(TIMEOUT):\n",
    "#         async with session.get(url) as resp:\n",
    "#             data = await resp.read()\n",
    "#             return resp.status, len(data)\n",
    "\n",
    "\n",
    "# async def fetch_with_retry(session, url):\n",
    "#     \"\"\"Retry wrapper with exponential backoff.\"\"\"\n",
    "#     for attempt in range(1, RETRIES + 1):\n",
    "#         try:\n",
    "#             async with semaphore:\n",
    "#                 status, size = await fetch(session, url)\n",
    "#                 return {\"url\": url, \"status\": status, \"size\": size, \"error\": None}\n",
    "#         except Exception as e:\n",
    "#             if attempt == RETRIES:\n",
    "#                 return {\"url\": url, \"status\": None, \"size\": None, \"error\": str(e)}\n",
    "            \n",
    "#             await asyncio.sleep(0.2 * (2 ** attempt) + random.random() * 0.1)\n",
    "\n",
    "\n",
    "# async def fetch_all(urls):\n",
    "#     conn = aiohttp.TCPConnector(\n",
    "#         limit=0,            # unlimited connections\n",
    "#         ttl_dns_cache=300   # keep DNS warm\n",
    "#     )\n",
    "#     timeout = aiohttp.ClientTimeout(total=None)\n",
    "\n",
    "#     async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "#         tasks = [asyncio.create_task(fetch_with_retry(session, url)) for url in urls]\n",
    "#         return await asyncio.gather(*tasks)\n",
    "\n",
    "\n",
    "# # entrypoint\n",
    "# if __name__ == \"__main__\":\n",
    "#     urls = [\n",
    "#         \"https://google.com\",\n",
    "#         \"https://yahoo.com\",\n",
    "#         \"https://bing.com\",\n",
    "#     ] * 1000  # simulate 3000 URLs\n",
    "\n",
    "#     start = time.time()\n",
    "#     results = asyncio.run(fetch_all(urls))\n",
    "#     duration = time.time() - start\n",
    "\n",
    "#     ok = sum(1 for r in results if r[\"error\"] is None)\n",
    "#     fail = len(results) - ok\n",
    "\n",
    "#     print(f\"Completed: {ok}, Failed: {fail}\")\n",
    "#     print(f\"Took {duration:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c5edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import asyncio\n",
    "# import aiohttp\n",
    "# import async_timeout\n",
    "# import requests\n",
    "# from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "\n",
    "# # -----------------------------------------------------------------------------\n",
    "# # Asyncio version\n",
    "# # -----------------------------------------------------------------------------\n",
    "\n",
    "# async def aio_fetch(session, url):\n",
    "#     async with async_timeout.timeout(5):\n",
    "#         async with session.get(url) as resp:\n",
    "#             await resp.read()\n",
    "#             return resp.status\n",
    "\n",
    "# async def aio_run(urls, max_con=200):\n",
    "#     connector = aiohttp.TCPConnector(limit=max_con)\n",
    "#     async with aiohttp.ClientSession(connector=connector) as session:\n",
    "#         tasks = [asyncio.create_task(aio_fetch(session, u)) for u in urls]\n",
    "#         await asyncio.gather(*tasks)\n",
    "\n",
    "\n",
    "# # -----------------------------------------------------------------------------\n",
    "# # ThreadPool version\n",
    "# # -----------------------------------------------------------------------------\n",
    "\n",
    "# def requests_fetch(url):\n",
    "#     r = requests.get(url, timeout=5)\n",
    "#     return r.status_code\n",
    "\n",
    "# def threads_run(urls, workers=200):\n",
    "#     with ThreadPoolExecutor(max_workers=workers) as ex:\n",
    "#         list(ex.map(requests_fetch, urls))\n",
    "\n",
    "\n",
    "# # -----------------------------------------------------------------------------\n",
    "# # ProcessPool version (will be terrible)\n",
    "# # -----------------------------------------------------------------------------\n",
    "\n",
    "# def requests_fetch_process(url):\n",
    "#     r = requests.get(url, timeout=5)\n",
    "#     return r.status_code\n",
    "\n",
    "# def processes_run(urls, workers=20):\n",
    "#     with ProcessPoolExecutor(max_workers=workers) as ex:\n",
    "#         list(ex.map(requests_fetch_process, urls))\n",
    "\n",
    "\n",
    "# # -----------------------------------------------------------------------------\n",
    "# # Benchmark runner\n",
    "# # -----------------------------------------------------------------------------\n",
    "\n",
    "# def bench(name, fn):\n",
    "#     print(f\"\\n=== Running: {name} ===\")\n",
    "#     start = time.time()\n",
    "#     fn()\n",
    "#     dur = time.time() - start\n",
    "#     print(f\"{name}: {dur:.2f} seconds\")\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     urls = [\"https://google.com\"] * 2000\n",
    "\n",
    "#     bench(\"asyncio + aiohttp\", lambda: asyncio.run(aio_run(urls, max_con=500)))\n",
    "#     bench(\"ThreadPoolExecutor + requests\", lambda: threads_run(urls, workers=200))\n",
    "#     bench(\"ProcessPoolExecutor\", lambda: processes_run(urls, workers=20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
